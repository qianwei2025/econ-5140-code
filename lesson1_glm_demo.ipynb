{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ECON 5140: Applied Econometrics\n",
        "## Lesson 1: Generalized Linear Models (GLM) - Tech Company Examples\n",
        "\n",
        "This notebook demonstrates GLM methods using real-world examples from tech companies.\n",
        "\n",
        "**Topics covered:**\n",
        "1. Binary outcomes: Logistic and Probit regression (ad click prediction)\n",
        "2. Count outcomes: Poisson regression (API usage/website visits)\n",
        "3. Model comparison and interpretation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.discrete.discrete_model import Logit, Probit\n",
        "from statsmodels.genmod.generalized_linear_model import GLM\n",
        "from statsmodels.genmod import families\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "\n",
        "# Set style for better-looking plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Binary Outcomes - Ad Click Prediction\n",
        "\n",
        "**Scenario:** A tech company wants to predict whether users will click on an advertisement based on:\n",
        "- Time spent on website (minutes)\n",
        "- Number of previous purchases\n",
        "- User age\n",
        "- Whether user is a premium member (0/1)\n",
        "\n",
        "This is a classic binary classification problem where OLS fails because:\n",
        "- Predictions can be outside [0,1]\n",
        "- Errors are heteroskedastic\n",
        "- We need to model probabilities, not outcomes directly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Generate latent variable and binary outcome\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Using probit structure: Y* = X*beta + epsilon, Y = 1 if Y* > 0\u001b[39;00m\n\u001b[32m     22\u001b[39m epsilon = np.random.normal(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, n)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m y_star = \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_true\u001b[49m + epsilon\n\u001b[32m     24\u001b[39m y_binary = (y_star > \u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 5)"
          ]
        }
      ],
      "source": [
        "# Generate synthetic data for ad click prediction\n",
        "n = 2000\n",
        "\n",
        "# Generate covariates\n",
        "time_on_site = np.random.exponential(5, n)  # Time in minutes\n",
        "previous_purchases = np.random.poisson(2, n)  # Count of previous purchases\n",
        "age = np.random.normal(35, 10, n).clip(18, 65)  # Age between 18-65\n",
        "premium_member = np.random.binomial(1, 0.3, n)  # 30% are premium members\n",
        "\n",
        "# True coefficients (latent variable model)\n",
        "# [intercept, time_on_site, previous_purchases, age, premium_member]\n",
        "beta_true = np.array([-2.0, 0.5, 0.3, -0.02, 1.2])\n",
        "X = np.column_stack([\n",
        "    np.ones(n),\n",
        "    time_on_site,\n",
        "    previous_purchases,\n",
        "    age,\n",
        "    premium_member\n",
        "])\n",
        "\n",
        "# Generate latent variable and binary outcome\n",
        "# Using probit structure: Y* = X*beta + epsilon, Y = 1 if Y* > 0\n",
        "epsilon = np.random.normal(0, 1, n)\n",
        "y_star = X @ beta_true + epsilon\n",
        "y_binary = (y_star > 0).astype(int)\n",
        "\n",
        "# Create DataFrame\n",
        "df_clicks = pd.DataFrame({\n",
        "    'clicked': y_binary,\n",
        "    'time_on_site': time_on_site,\n",
        "    'previous_purchases': previous_purchases,\n",
        "    'age': age,\n",
        "    'premium_member': premium_member\n",
        "})\n",
        "\n",
        "print(\"Dataset Summary:\")\n",
        "print(df_clicks.describe())\n",
        "print(f\"\\nClick rate: {df_clicks['clicked'].mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why OLS Fails for Binary Outcomes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try OLS on binary outcome\n",
        "X_ols = sm.add_constant(df_clicks[['time_on_site', 'previous_purchases', 'age', 'premium_member']])\n",
        "ols_model = sm.OLS(df_clicks['clicked'], X_ols).fit()\n",
        "\n",
        "# Predict probabilities\n",
        "ols_pred = ols_model.predict(X_ols)\n",
        "\n",
        "print(\"OLS Model Results:\")\n",
        "print(ols_model.summary().tables[1])\n",
        "print(f\"\\nMinimum predicted value: {ols_pred.min():.4f}\")\n",
        "print(f\"Maximum predicted value: {ols_pred.max():.4f}\")\n",
        "print(f\"Predictions outside [0,1]: {((ols_pred < 0) | (ols_pred > 1)).sum()} out of {len(ols_pred)}\")\n",
        "\n",
        "# Visualize the problem\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Predicted probabilities vs actual\n",
        "axes[0].scatter(df_clicks['time_on_site'], ols_pred, alpha=0.3, label='OLS predictions')\n",
        "axes[0].axhline(y=0, color='r', linestyle='--', label='Valid range [0,1]')\n",
        "axes[0].axhline(y=1, color='r', linestyle='--')\n",
        "axes[0].set_xlabel('Time on Site (minutes)')\n",
        "axes[0].set_ylabel('Predicted Probability')\n",
        "axes[0].set_title('OLS: Predictions Can Be Outside [0,1]')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Distribution of predictions\n",
        "axes[1].hist(ols_pred, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Valid range')\n",
        "axes[1].axvline(x=1, color='r', linestyle='--', linewidth=2)\n",
        "axes[1].set_xlabel('Predicted Probability')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Distribution of OLS Predictions')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression (Logit Model)\n",
        "\n",
        "The logit model uses the sigmoid function to map the linear predictor to valid probabilities:\n",
        "\n",
        "$$P(Y=1|X) = \\frac{1}{1 + e^{-X\\beta}}$$\n",
        "\n",
        "Or equivalently: $\\log\\left(\\frac{p}{1-p}\\right) = X\\beta$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit logistic regression\n",
        "X_logit = sm.add_constant(df_clicks[['time_on_site', 'previous_purchases', 'age', 'premium_member']])\n",
        "logit_model = Logit(df_clicks['clicked'], X_logit).fit()\n",
        "\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(logit_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predicted probabilities from logit\n",
        "logit_pred = logit_model.predict(X_logit)\n",
        "\n",
        "# Calculate marginal effects (average marginal effects)\n",
        "# For logit: ME = beta * p * (1-p)\n",
        "marginal_effects = logit_model.get_margeff()\n",
        "print(\"\\nAverage Marginal Effects (Logit):\")\n",
        "print(marginal_effects.summary())\n",
        "\n",
        "# Visualize logit predictions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Predicted probabilities\n",
        "axes[0].scatter(df_clicks['time_on_site'], logit_pred, alpha=0.3, c=df_clicks['clicked'], \n",
        "                cmap='RdYlGn', s=20)\n",
        "axes[0].set_xlabel('Time on Site (minutes)')\n",
        "axes[0].set_ylabel('Predicted Probability (Logit)')\n",
        "axes[0].set_title('Logit: All Predictions in [0,1]')\n",
        "axes[0].axhline(y=0.5, color='k', linestyle='--', alpha=0.5, label='Decision boundary (0.5)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: S-shaped curve\n",
        "sorted_idx = np.argsort(df_clicks['time_on_site'])\n",
        "axes[1].plot(df_clicks['time_on_site'].values[sorted_idx], \n",
        "             logit_pred.values[sorted_idx], 'b-', linewidth=2, label='Logit prediction')\n",
        "axes[1].scatter(df_clicks['time_on_site'], df_clicks['clicked'], \n",
        "                alpha=0.2, s=10, color='gray', label='Actual outcomes')\n",
        "axes[1].set_xlabel('Time on Site (minutes)')\n",
        "axes[1].set_ylabel('Probability of Click')\n",
        "axes[1].set_title('Sigmoid Function: S-Shaped Probability Curve')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nLogit predictions range: [{logit_pred.min():.4f}, {logit_pred.max():.4f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Probit Regression\n",
        "\n",
        "The probit model uses the standard normal CDF to map the linear predictor to probabilities:\n",
        "\n",
        "$$P(Y=1|X) = \\Phi(X\\beta)$$\n",
        "\n",
        "where $\\Phi(\\cdot)$ is the standard normal cumulative distribution function.\n",
        "\n",
        "**Latent variable interpretation:** $Y^* = X\\beta + \\varepsilon$, where $\\varepsilon \\sim N(0,1)$, and $Y = 1$ if $Y^* > 0$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit probit regression\n",
        "probit_model = Probit(df_clicks['clicked'], X_logit).fit()\n",
        "\n",
        "print(\"Probit Regression Results:\")\n",
        "print(probit_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predicted probabilities from probit\n",
        "probit_pred = probit_model.predict(X_logit)\n",
        "\n",
        "# Calculate marginal effects for probit\n",
        "probit_marginal_effects = probit_model.get_margeff()\n",
        "print(\"\\nAverage Marginal Effects (Probit):\")\n",
        "print(probit_marginal_effects.summary())\n",
        "\n",
        "# Compare logit and probit\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Compare predictions\n",
        "sorted_idx = np.argsort(df_clicks['time_on_site'])\n",
        "axes[0].plot(df_clicks['time_on_site'].values[sorted_idx], \n",
        "             logit_pred.values[sorted_idx], 'b-', linewidth=2, label='Logit')\n",
        "axes[0].plot(df_clicks['time_on_site'].values[sorted_idx], \n",
        "             probit_pred.values[sorted_idx], 'r--', linewidth=2, label='Probit')\n",
        "axes[0].set_xlabel('Time on Site (minutes)')\n",
        "axes[0].set_ylabel('Predicted Probability')\n",
        "axes[0].set_title('Logit vs Probit: Very Similar Predictions')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Scatter of logit vs probit predictions\n",
        "axes[1].scatter(logit_pred, probit_pred, alpha=0.3)\n",
        "axes[1].plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect agreement')\n",
        "axes[1].set_xlabel('Logit Predictions')\n",
        "axes[1].set_ylabel('Probit Predictions')\n",
        "axes[1].set_title('Logit vs Probit: Correlation')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nCorrelation between logit and probit predictions: {np.corrcoef(logit_pred, probit_pred)[0,1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Comparison: Logit vs Probit\n",
        "\n",
        "**Key takeaways:**\n",
        "- Both models produce very similar predictions\n",
        "- Coefficients differ in scale (probit coefficients are typically smaller)\n",
        "- Marginal effects are usually very similar\n",
        "- Choice rarely changes substantive conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare coefficients (note: probit coefficients are typically smaller)\n",
        "comparison = pd.DataFrame({\n",
        "    'Logit': logit_model.params,\n",
        "    'Probit': probit_model.params,\n",
        "    'Logit_ME': marginal_effects.margeff,\n",
        "    'Probit_ME': probit_marginal_effects.margeff\n",
        "})\n",
        "comparison['Ratio_Logit_Probit'] = comparison['Logit'] / comparison['Probit']\n",
        "\n",
        "print(\"Coefficient Comparison:\")\n",
        "print(comparison.round(4))\n",
        "\n",
        "# Compare model fit\n",
        "print(\"\\nModel Fit Comparison:\")\n",
        "print(f\"Logit Log-Likelihood: {logit_model.llf:.2f}\")\n",
        "print(f\"Probit Log-Likelihood: {probit_model.llf:.2f}\")\n",
        "print(f\"Logit AIC: {logit_model.aic:.2f}\")\n",
        "print(f\"Probit AIC: {probit_model.aic:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Count Outcomes - API Usage Prediction\n",
        "\n",
        "**Scenario:** A cloud service provider wants to predict the number of API calls made by customers based on:\n",
        "- Subscription tier (free, basic, premium)\n",
        "- Number of active users\n",
        "- Days since account creation\n",
        "- Monthly subscription fee\n",
        "\n",
        "This is a count outcome problem where:\n",
        "- Outcomes are non-negative integers (0, 1, 2, ...)\n",
        "- Variance increases with the mean\n",
        "- OLS can produce negative predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic data for API usage\n",
        "n_count = 1500\n",
        "\n",
        "# Generate covariates\n",
        "subscription_tier = np.random.choice([0, 1, 2], n_count, p=[0.4, 0.4, 0.2])  # 0=free, 1=basic, 2=premium\n",
        "active_users = np.random.poisson(50, n_count).clip(1, 200)\n",
        "days_since_creation = np.random.exponential(365, n_count).clip(1, 2000)\n",
        "monthly_fee = np.where(subscription_tier == 0, 0,\n",
        "                       np.where(subscription_tier == 1, \n",
        "                                np.random.normal(50, 10, n_count),\n",
        "                                np.random.normal(150, 30, n_count))).clip(0)\n",
        "\n",
        "# True coefficients for Poisson (on log scale)\n",
        "beta_count_true = np.array([3.0, 0.5, 0.8, 0.01, 0.005])\n",
        "X_count = np.column_stack([\n",
        "    np.ones(n_count),\n",
        "    subscription_tier,\n",
        "    np.log(active_users + 1),  # Log transform for better fit\n",
        "    days_since_creation / 100,  # Scale for interpretation\n",
        "    monthly_fee / 100\n",
        "])\n",
        "\n",
        "# Generate count outcome using Poisson\n",
        "# log(mu) = X*beta, so mu = exp(X*beta)\n",
        "mu_true = np.exp(X_count @ beta_count_true)\n",
        "y_count = np.random.poisson(mu_true)\n",
        "\n",
        "# Create DataFrame\n",
        "df_api = pd.DataFrame({\n",
        "    'api_calls': y_count,\n",
        "    'subscription_tier': subscription_tier,\n",
        "    'active_users': active_users,\n",
        "    'days_since_creation': days_since_creation,\n",
        "    'monthly_fee': monthly_fee\n",
        "})\n",
        "\n",
        "print(\"API Usage Dataset Summary:\")\n",
        "print(df_api.describe())\n",
        "print(f\"\\nMean API calls: {df_api['api_calls'].mean():.2f}\")\n",
        "print(f\"Variance of API calls: {df_api['api_calls'].var():.2f}\")\n",
        "print(f\"Variance/Mean ratio: {df_api['api_calls'].var() / df_api['api_calls'].mean():.2f}\")\n",
        "print(\"(For Poisson, this should be close to 1)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why OLS Fails for Count Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try OLS on count outcome\n",
        "X_count_ols = sm.add_constant(df_api[['subscription_tier', 'active_users', \n",
        "                                       'days_since_creation', 'monthly_fee']])\n",
        "ols_count_model = sm.OLS(df_api['api_calls'], X_count_ols).fit()\n",
        "\n",
        "# Predict counts\n",
        "ols_count_pred = ols_count_model.predict(X_count_ols)\n",
        "\n",
        "print(\"OLS Model Results (Count Outcome):\")\n",
        "print(ols_count_model.summary().tables[1])\n",
        "print(f\"\\nMinimum predicted value: {ols_count_pred.min():.2f}\")\n",
        "print(f\"Maximum predicted value: {ols_count_pred.max():.2f}\")\n",
        "print(f\"Negative predictions: {(ols_count_pred < 0).sum()} out of {len(ols_count_pred)}\")\n",
        "\n",
        "# Visualize the problem\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Predictions vs actual\n",
        "axes[0].scatter(df_api['active_users'], ols_count_pred, alpha=0.3, label='OLS predictions')\n",
        "axes[0].scatter(df_api['active_users'], df_api['api_calls'], alpha=0.2, \n",
        "                color='red', s=10, label='Actual counts')\n",
        "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2, label='Valid range (â‰¥0)')\n",
        "axes[0].set_xlabel('Active Users')\n",
        "axes[0].set_ylabel('Predicted API Calls')\n",
        "axes[0].set_title('OLS: Can Produce Negative Predictions')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Distribution of predictions\n",
        "axes[1].hist(ols_count_pred, bins=50, edgecolor='black', alpha=0.7, label='OLS predictions')\n",
        "axes[1].hist(df_api['api_calls'], bins=50, edgecolor='black', alpha=0.5, \n",
        "             color='red', label='Actual counts')\n",
        "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[1].set_xlabel('API Calls')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Distribution: OLS vs Actual')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Poisson Regression\n",
        "\n",
        "Poisson regression models count outcomes using:\n",
        "\n",
        "- **Distribution:** $Y|X \\sim \\text{Poisson}(\\mu)$\n",
        "- **Link function:** $\\log(\\mu) = X\\beta$ (canonical log link)\n",
        "- **Properties:** $E[Y|X] = \\mu$, $\\text{Var}(Y|X) = \\mu$\n",
        "\n",
        "**Interpretation:** Coefficients are on the log-count scale. A one-unit increase in $X_k$ multiplies the expected count by $e^{\\beta_k}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Poisson regression\n",
        "X_poisson = sm.add_constant(pd.DataFrame({\n",
        "    'subscription_tier': df_api['subscription_tier'],\n",
        "    'log_active_users': np.log(df_api['active_users'] + 1),\n",
        "    'days_scaled': df_api['days_since_creation'] / 100,\n",
        "    'fee_scaled': df_api['monthly_fee'] / 100\n",
        "}))\n",
        "\n",
        "# Fit Poisson regression\n",
        "poisson_model = GLM(df_api['api_calls'], X_poisson, family=families.Poisson()).fit()\n",
        "\n",
        "print(\"Poisson Regression Results:\")\n",
        "print(poisson_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predicted counts\n",
        "poisson_pred = poisson_model.predict(X_poisson)\n",
        "\n",
        "# Interpret coefficients\n",
        "print(\"\\nCoefficient Interpretation:\")\n",
        "print(\"=\" * 60)\n",
        "coef_names = ['Intercept', 'Subscription Tier', 'Log(Active Users)', \n",
        "              'Days (scaled)', 'Monthly Fee (scaled)']\n",
        "for i, (name, coef) in enumerate(zip(coef_names, poisson_model.params)):\n",
        "    if i == 0:\n",
        "        print(f\"{name}: {coef:.4f}\")\n",
        "    else:\n",
        "        pct_change = (np.exp(coef) - 1) * 100\n",
        "        print(f\"{name}: {coef:.4f} (exp({coef:.4f}) = {np.exp(coef):.4f}, \"\n",
        "              f\"{pct_change:+.2f}% change per unit)\")\n",
        "\n",
        "# Visualize Poisson model\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Predictions vs actual\n",
        "axes[0].scatter(df_api['active_users'], poisson_pred, alpha=0.3, \n",
        "                label='Poisson predictions', s=20)\n",
        "axes[0].scatter(df_api['active_users'], df_api['api_calls'], alpha=0.2, \n",
        "                color='red', s=10, label='Actual counts')\n",
        "axes[0].set_xlabel('Active Users')\n",
        "axes[0].set_ylabel('Predicted API Calls')\n",
        "axes[0].set_title('Poisson: All Predictions Non-Negative')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Distribution comparison\n",
        "axes[1].hist(poisson_pred, bins=50, edgecolor='black', alpha=0.7, \n",
        "             label='Poisson predictions', density=True)\n",
        "axes[1].hist(df_api['api_calls'], bins=50, edgecolor='black', alpha=0.5, \n",
        "             color='red', label='Actual counts', density=True)\n",
        "axes[1].set_xlabel('API Calls')\n",
        "axes[1].set_ylabel('Density')\n",
        "axes[1].set_title('Distribution: Poisson vs Actual')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nPoisson predictions range: [{poisson_pred.min():.2f}, {poisson_pred.max():.2f}]\")\n",
        "print(f\"Negative predictions: {(poisson_pred < 0).sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Comparison: OLS vs Poisson\n",
        "\n",
        "**Key differences:**\n",
        "- OLS can produce negative predictions (invalid for counts)\n",
        "- Poisson ensures non-negative predictions\n",
        "- Poisson accounts for mean-variance relationship\n",
        "- Poisson coefficients have multiplicative interpretation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare model performance\n",
        "comparison_count = pd.DataFrame({\n",
        "    'Actual': df_api['api_calls'],\n",
        "    'OLS': ols_count_pred,\n",
        "    'Poisson': poisson_pred\n",
        "})\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"Model Comparison:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"OLS - Negative predictions: {(ols_count_pred < 0).sum()}\")\n",
        "print(f\"Poisson - Negative predictions: {(poisson_pred < 0).sum()}\")\n",
        "print(f\"\\nOLS - Mean Absolute Error: {np.mean(np.abs(df_api['api_calls'] - ols_count_pred)):.2f}\")\n",
        "print(f\"Poisson - Mean Absolute Error: {np.mean(np.abs(df_api['api_calls'] - poisson_pred)):.2f}\")\n",
        "print(f\"\\nOLS - R-squared: {ols_count_model.rsquared:.4f}\")\n",
        "print(f\"Poisson - Pseudo R-squared: {poisson_model.pseudo_rsquared():.4f}\")\n",
        "\n",
        "# Visualize comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Predictions comparison\n",
        "axes[0].scatter(df_api['api_calls'], ols_count_pred, alpha=0.3, label='OLS', s=20)\n",
        "axes[0].scatter(df_api['api_calls'], poisson_pred, alpha=0.3, label='Poisson', s=20)\n",
        "axes[0].plot([0, df_api['api_calls'].max()], [0, df_api['api_calls'].max()], \n",
        "             'r--', linewidth=2, label='Perfect prediction')\n",
        "axes[0].set_xlabel('Actual API Calls')\n",
        "axes[0].set_ylabel('Predicted API Calls')\n",
        "axes[0].set_title('Prediction Comparison')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Residuals\n",
        "ols_residuals = df_api['api_calls'] - ols_count_pred\n",
        "poisson_residuals = df_api['api_calls'] - poisson_pred\n",
        "\n",
        "axes[1].scatter(ols_count_pred, ols_residuals, alpha=0.3, label='OLS residuals', s=20)\n",
        "axes[1].scatter(poisson_pred, poisson_residuals, alpha=0.3, label='Poisson residuals', s=20)\n",
        "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[1].set_xlabel('Predicted API Calls')\n",
        "axes[1].set_ylabel('Residuals')\n",
        "axes[1].set_title('Residual Analysis')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: GLM Framework\n",
        "\n",
        "This notebook demonstrated the GLM framework with tech company examples:\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "1. **Binary Outcomes (Logit/Probit):**\n",
        "   - OLS fails because predictions can be outside [0,1]\n",
        "   - Logit and probit use nonlinear link functions to ensure valid probabilities\n",
        "   - Both models produce very similar results\n",
        "   - Coefficients need to be interpreted via marginal effects or odds ratios\n",
        "\n",
        "2. **Count Outcomes (Poisson):**\n",
        "   - OLS fails because predictions can be negative\n",
        "   - Poisson regression uses log link to ensure non-negative predictions\n",
        "   - Coefficients have multiplicative interpretation\n",
        "   - Accounts for mean-variance relationship\n",
        "\n",
        "3. **GLM Structure:**\n",
        "   - All GLMs share: Linear predictor $\\eta = X\\beta$\n",
        "   - They differ in: Distribution + Link function\n",
        "   - Estimation via maximum likelihood\n",
        "\n",
        "### When to Use Each Model:\n",
        "\n",
        "| Outcome Type | Model | Example |\n",
        "|-------------|-------|---------|\n",
        "| Continuous | OLS | Revenue, prices |\n",
        "| Binary | Logit/Probit | Click, purchase, default |\n",
        "| Count | Poisson | API calls, visits, patents |\n",
        "| Ordered categories | Ordered logit/probit | Rating scales, education levels |\n",
        "| Unordered categories | Multinomial logit | Brand choice, transportation mode |\n",
        "\n",
        "**Remember:** Choose the model based on the outcome distribution, not just convenience!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "- ECON 5140: Applied Econometrics, Lesson 1 - Generalized Linear Models\n",
        "- Statsmodels documentation: https://www.statsmodels.org/\n",
        "- Cameron, A. C., & Trivedi, P. K. (2013). *Regression Analysis of Count Data*\n",
        "- Wooldridge, J. M. (2010). *Econometric Analysis of Cross Section and Panel Data*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
